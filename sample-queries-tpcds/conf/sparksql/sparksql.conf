## configurations for Spark
spark.sql.warehouse.dir=/user/hive/warehouse
#spark.sql.hive.convertMetastoreOrc=true
spark.master=yarn
spark.deploy.mode=client
spark.executor.cores=4
spark.executor.memory=16g
spark.yarn.executor.memoryOverhead=3072
spark.driver.memory=30g
spark.driver.maxResultSize=3g
spark.dynamicAllocation.enabled=true
spark.shuffle.service.enabled=true
spark.network.timeout=3600s
spark.default.parallelism=288
spark.sql.shuffle.partitions=288
spark.executor.extraJavaOptions=-XX:+UseParallelOldGC -XX:ParallelGCThreads=8 -XX:NewRatio=1 -XX:SurvivorRatio=1
spark.driver.extraJavaOptions=-XX:+UseParallelOldGC -XX:ParallelGCThreads=8 -XX:NewRatio=1 -XX:SurvivorRatio=1
spark.sql.autoBroadcastJoinThreshold=1073741824
#spark.sql.autoBroadcastJoinThreshold=8589934592

spark.eventLog.enabled=true
spark.yarn.historyServer.address=redhat-master:18080
spark.history.ui.port=18080
spark.eventLog.dir=hdfs://redhat-master:8020/user/spark/applicationHistory
spark.history.fs.logDirectory=hdfs://redhat-master:8020/user/spark/applicationHistory
spark.shuffle.registration.timeout=1200000
spark.local.dir=/mnt/disk1/spark_local,/mnt/disk2/spark_local,/mnt/disk3/spark_local,/mnt/disk4/spark_local,/mnt/disk5/spark_local,/mnt/disk6/spark_local,/mnt/disk7/spark_local,/mnt/disk8/spark_local

spark.sql.warehouse.dir=/user/hive/warehouse
spark.sql.hive.metastore.version=2.1.0
spark.sql.hive.metastore.jars=/opt/dars/hive235/lib/*
